---
typora-root-url: snapshotimg
---

## 1 集成方法之快照集成（Snapshot Ensembling）

论文基于cos循环的学习策略，提出了快照集成（snapshot ensembles），只需要一次训练就可以得到收敛于多个不同最小值处的模型，从而进行模型集成。使用集成模型相比单模型可以获得更大的准确性。在CIFAR-10 上错误率为3.4%，在CIFAR-100 上错误率为17.4%。

### 1.1 SNAPSHOT ENSEMBLING

![1](/1.PNG)

左图为使用传统的学习率不断下降的学习策略。

右图为使用cos方式的学习率不断循环下降，上升的策略。可以看出该方式可以收敛到多个全局最小值。从而可以使用这些模型进行集成学习。

使用传统学习率训练的单个模型，模型精度可能会比使用cos方式训练的每个模型的精度都略高。但是cos方式的模型进行集成后，效果会优于传统方式训练的单个模型。

使用Snapshot Ensembling得到的多个模型具有下面2个性质：

1. 每个模型都有比较低的错误率

2. 模型两两之间对识别错误的例子没有交集

   基于这2个性质就可以进行模型集成

   ![2](/2.PNG)

   

###  1.2 Cyclic Cosine Annealing

![3](/3.PNG)

t:迭代的次数

T:一共的训练次数

f:cos方式的循环递减函数

M:循环的cycle次数

其中，初始学习率为a=f(0),最终学习率为a= f(T/M)

实验中将f定义为cos形式的函数

![4](/4.PNG)



### 1.3实验结果

​	![5](/5.PNG)

![6](/6.PNG)

![7](/7.PNG)

可以看到Snapshot Ensembling要优于不同方式训练的模型集成。

传统的模型集成，需要训练不同的模型，如果需要n个模型则需要n次的训练时间，而Snapshot Ensembling需要n个模型只需要1次的训练时间，在训练过程设置n:循环的cycle次数,就可以得到n个模型。一般是在每一个周期学习率最小的时候保存模型。